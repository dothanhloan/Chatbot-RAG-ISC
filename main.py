import os
import sys

# ==============================================================================
# ğŸ‘‡ KHU Vá»°C ÄIá»€N CHÃŒA KHÃ“A (Cáº¦N Cáº¢ 2 CÃI)
# ==============================================================================

# 1. KEY GOOGLE Má»šI (Äá»ƒ lÃ m "Máº¯t" Ä‘á»c tÃ i liá»‡u)
# ğŸ‘‰ Láº¥y táº¡i: aistudio.google.com (Táº¡o Project má»›i cho sáº¡ch lá»—i)
KEY_GOOGLE_MOI = ""

# 2. KEY GROQ (Äá»ƒ lÃ m "NÃ£o" tráº£ lá»i)
# ğŸ‘‰ Láº¥y táº¡i: console.groq.com
KEY_GROQ_CUA_BAN = ""

# ==============================================================================

os.environ["GOOGLE_API_KEY"] = KEY_GOOGLE_MOI
GROQ_API_KEY = KEY_GROQ_CUA_BAN

try:
    from langchain_community.document_loaders import Docx2txtLoader
    from langchain_text_splitters import CharacterTextSplitter   # âœ… Sá»¬A á» ÄÃ‚Y
    from langchain_community.vectorstores import FAISS
    from langchain_groq import ChatGroq
    from langchain_core.prompts import ChatPromptTemplate
except ImportError as e:
    print("âŒ Thiáº¿u thÆ° viá»‡n hoáº·c xung Ä‘á»™t mÃ´i trÆ°á»ng:", e)
    print("ğŸ‘‰ Cháº¡y: py -3.12 -m pip install langchain langchain-groq langchain-community faiss-cpu docx2txt")
    sys.exit(1)


def main():
    file_path = "data/input.docx"
    if not os.path.exists(file_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file '{file_path}'")
        return

    print("ğŸ“„ Äang Ä‘á»c tÃ i liá»‡u...")
    loader = Docx2txtLoader(file_path)
    docs = loader.load()
    splits = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)


    # ---------------------------------------------------------
    # 1. Bá»˜ NHá»š (EMBEDDING) -> Báº®T BUá»˜C DÃ™NG GOOGLE MODEL NÃ€Y
    # ---------------------------------------------------------
    print("ğŸ§  Äang náº¡p bá»™ nhá»› (Google Embedding)...")
    from langchain_google_genai import GoogleGenerativeAIEmbeddings

    try:
        embeddings = GoogleGenerativeAIEmbeddings(
            # ğŸ‘‡ KHÃ”NG ÄÆ¯á»¢C Äá»”I TÃŠN MODEL NÃ€Y ğŸ‘‡
            model="models/text-embedding-004", 
            google_api_key=os.environ["GOOGLE_API_KEY"]
        )
        vectorstore = FAISS.from_documents(splits, embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    except Exception as e:
        print(f"âŒ Lá»—i Key Google: {e}")
        print("ğŸ‘‰ Lá»i khuyÃªn: Táº¡o Key Google má»›i táº¡i aistudio.google.com rá»“i thay vÃ o dÃ²ng sá»‘ 9.")
        return

    # ---------------------------------------------------------
    # 2. Bá»˜ NÃƒO (CHAT) -> DÃ™NG GROQ MODEL NÃ€Y
    # ---------------------------------------------------------
    print("ğŸ”Œ Äang káº¿t ná»‘i nÃ£o bá»™ Groq (Llama 3.3)...")
    try:
        llm = ChatGroq(
            temperature=0,
            # ğŸ‘‡ MODEL Má»šI NHáº¤T Cá»¦A GROQ ğŸ‘‡
            model_name="llama-3.3-70b-versatile", 
            api_key=GROQ_API_KEY
        )
    except Exception as e:
        print(f"âŒ Lá»—i Key Groq: {e}")
        return

    prompt = ChatPromptTemplate.from_template(
        "Dá»±a vÃ o vÄƒn báº£n: {context}\n\nTráº£ lá»i cÃ¢u há»i: {question}"
    )

    print("\n" + "="*40)
    print("ğŸš€ CHATBOT GROQ (LLAMA 3.3) Sáº´N SÃ€NG!")
    print("="*40)

    while True:
        try:
            q = input("\nğŸ‘¤ Báº¡n: ")
            if q.lower() in ["exit", "thoÃ¡t"]: break
            if not q.strip(): continue

            print("ğŸ¤– Bot: Äang suy nghÄ©...", end="\r")
            
            relevant_docs = retriever.invoke(q)
            context = "\n".join([d.page_content for d in relevant_docs])
            res = (prompt | llm).invoke({"context": context, "question": q})
            print(f"\nğŸ’¡ Tráº£ lá»i: {res.content}")
            
        except Exception as e:
            print(f"\nâŒ Lá»—i: {e}")

if __name__ == "__main__":
    main()