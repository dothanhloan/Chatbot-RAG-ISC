import streamlit as st
import os

# --- 1. C·∫§U H√åNH API KEY (QUAN TR·ªåNG NH·∫§T) ---
# ƒêo·∫°n n√†y gi√∫p t·ª± ƒë·ªông l·∫•y Key t·ª´ "Secrets" (n·∫øu tr√™n Web) ho·∫∑c ".env" (n·∫øu d∆∞·ªõi m√°y)
if "GROQ_API_KEY" in st.secrets:
    # N·∫øu ch·∫°y tr√™n Streamlit Cloud -> L·∫•y t·ª´ Secrets
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
else:
    # N·∫øu ch·∫°y d∆∞·ªõi m√°y Local -> L·∫•y t·ª´ file .env
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        pass

# Ki·ªÉm tra l·∫ßn cu·ªëi, n·∫øu v·∫´n kh√¥ng c√≥ Key th√¨ d·ª´ng l·∫°i b√°o l·ªói
if not os.environ.get("GROQ_API_KEY"):
    st.error("‚ùå L·ªói: Ch∆∞a t√¨m th·∫•y GROQ_API_KEY! H√£y c·∫•u h√¨nh trong file .env (Local) ho·∫∑c m·ª•c Secrets (Cloud).")
    st.stop()

# --- 2. IMPORT TH∆Ø VI·ªÜN ---
from langchain_community.document_loaders import Docx2txtLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate

# --- 3. C·∫§U H√åNH TRANG WEB ---
st.set_page_config(page_title="ICS Chatbot", page_icon="üõ°Ô∏è")
st.title("üõ°Ô∏è Tr·ª£ l√Ω ·∫£o ICS Security")
st.markdown("H·ªèi ƒë√°p v·ªÅ gi·∫£i ph√°p b·∫£o m·∫≠t **VietGuard**, **AI SOC** v√† ti√™u chu·∫©n **ISO 27001** c·ªßa ICS.")

# --- 4. H√ÄM N·∫†P D·ªÆ LI·ªÜU (CACHE ƒê·ªÇ KH√îNG PH·∫¢I LOAD L·∫†I) ---
@st.cache_resource
def load_and_process_data():
    # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng. 
    # L∆∞u √Ω: Theo c·∫•u tr√∫c GitHub c·ªßa b·∫°n [1], file c√≥ th·ªÉ n·∫±m trong th∆∞ m·ª•c 'data/' ho·∫∑c c√πng c·∫•p.
    # Code n√†y s·∫Ω th·ª≠ t√¨m c·∫£ 2 n∆°i.
    file_path = "input.docx"
    if not os.path.exists(file_path):
        file_path = "data/input.docx" # Th·ª≠ t√¨m trong th∆∞ m·ª•c data
        if not os.path.exists(file_path):
            return None

    # ƒê·ªçc t√†i li·ªáu
    loader = Docx2txtLoader(file_path)
    docs = loader.load()
    
    # C·∫Øt nh·ªè vƒÉn b·∫£n ƒë·ªÉ AI d·ªÖ ƒë·ªçc
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.split_documents(docs)
    
    # T·∫°o Vector Database (B·ªô nh·ªõ)
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.from_documents(chunks, embeddings)
    return vectorstore

# --- 5. KH·ªûI T·∫†O H·ªÜ TH·ªêNG ---
with st.spinner("ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng tri th·ª©c ICS..."):
    vectorstore = load_and_process_data()

if vectorstore is None:
    st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file 'input.docx'. Vui l√≤ng ki·ªÉm tra l·∫°i th∆∞ m·ª•c d·ª± √°n!")
else:
    # C·∫•u h√¨nh "B·ªô n√£o" AI (Llama 3 tr√™n Groq)
    llm = ChatGroq(model_name="llama-3.3-70b-versatile", temperature=0.3)
    
    # T·∫°o khu√¥n m·∫´u c√¢u tr·∫£ l·ªùi chuy√™n nghi·ªáp
    template = """
    B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp c·ªßa C√¥ng ty C·ªï ph·∫ßn An ninh M·∫°ng Qu·ªëc t·∫ø (ICS).
    S·ª≠ d·ª•ng th√¥ng tin ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng.
    N·∫øu th√¥ng tin kh√¥ng c√≥ trong ng·ªØ c·∫£nh, h√£y n√≥i l√† b·∫°n ch∆∞a r√µ, ƒë·ª´ng b·ªãa ƒë·∫∑t.
    
    NG·ªÆ C·∫¢NH (Th√¥ng tin n·ªôi b·ªô ICS):
    {context}
    
    C√ÇU H·ªéI:
    {question}
    """
    prompt = ChatPromptTemplate.from_template(template)

    # --- 6. GIAO DI·ªÜN CHAT ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng nh·∫≠p c√¢u h·ªèi
    if question := st.chat_input("Nh·∫≠p c√¢u h·ªèi v·ªÅ ICS (VD: VietGuard l√† g√¨?)..."):
        # Hi·ªán c√¢u h·ªèi ng∆∞·ªùi d√πng
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        # AI suy nghƒ© v√† tr·∫£ l·ªùi
        with st.chat_message("assistant"):
            with st.spinner("ƒêang tra c·ª©u d·ªØ li·ªáu..."):
                try:
                    # 1. T√¨m ki·∫øm th√¥ng tin li√™n quan trong input.docx
                    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
                    relevant_docs = retriever.invoke(question)
                    context_text = "\n\n".join([d.page_content for d in relevant_docs])
                    
                    # 2. G·ª≠i cho AI t·ªïng h·ª£p
                    chain = prompt | llm
                    response = chain.invoke({"context": context_text, "question": question})
                    
                    st.markdown(response.content)
                    
                    # L∆∞u c√¢u tr·∫£ l·ªùi
                    st.session_state.messages.append({"role": "assistant", "content": response.content})
                except Exception as e:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói: {str(e)}")
